{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee812716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import openai\n",
    "\n",
    "from keymaker.models import chatgpt, gpt4, LlamaCpp\n",
    "from keymaker.constraints import RegexConstraint, OptionsConstraint\n",
    "from keymaker import Prompt, Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c40df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f5e901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model=chatgpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd8253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg = \"The weather will be really bad tomorrow what should I wear?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21629fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=f\"\"\"\n",
    "%system%You are an AI assistant that chooses tools for tasks based on a user task and tool descriptions.\n",
    "Here are the tools you can choose from:\n",
    "    Tool A: Looks up information on animals\n",
    "    Tool B: Finds peoples geolocation based on triangulating their phone data\n",
    "    Tool C: Finds the best outfit to wear today based on the weather\n",
    "%/system%\n",
    "%user%{user_msg}\n",
    "Explain your reasoning in 50 words or less and then choose the appropriate tool.\n",
    "%/user%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3664d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def print_stream(completion: Completion):\n",
    "    print(repr(completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c731ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbf61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text = 'Based', start = 502, stop = 507)\n",
      "Completion(text = ' on', start = 507, stop = 510)\n",
      "Completion(text = ' the', start = 510, stop = 514)\n",
      "Completion(text = ' user', start = 514, stop = 519)\n",
      "Completion(text = ''s', start = 519, stop = 521)\n",
      "Completion(text = ' request', start = 521, stop = 529)\n",
      "Completion(text = ' to', start = 529, stop = 532)\n",
      "Completion(text = ' find', start = 532, stop = 537)\n",
      "Completion(text = ' the', start = 537, stop = 541)\n",
      "Completion(text = ' best', start = 541, stop = 546)\n",
      "Completion(text = ' outfit', start = 546, stop = 553)\n",
      "Completion(text = ' to', start = 553, stop = 556)\n",
      "Completion(text = ' wear', start = 556, stop = 561)\n",
      "Completion(text = ' tomorrow', start = 561, stop = 570)\n",
      "Completion(text = ',', start = 570, stop = 571)\n",
      "Completion(text = ' the', start = 571, stop = 575)\n",
      "Completion(text = ' appropriate', start = 575, stop = 587)\n",
      "Completion(text = ' tool', start = 587, stop = 592)\n",
      "Completion(text = ' to', start = 592, stop = 595)\n",
      "Completion(text = ' use', start = 595, stop = 599)\n",
      "Completion(text = ' would', start = 599, stop = 605)\n",
      "Completion(text = ' be', start = 605, stop = 608)\n",
      "Completion(text = ' Tool', start = 608, stop = 613)\n",
      "Completion(text = ' C', start = 613, stop = 615)\n",
      "Completion(text = '.', start = 615, stop = 616)\n",
      "Completion(text = ' This', start = 616, stop = 621)\n",
      "Completion(text = ' tool', start = 621, stop = 626)\n",
      "Completion(text = ' can', start = 626, stop = 630)\n",
      "Completion(text = ' analyze', start = 630, stop = 638)\n",
      "Completion(text = ' the', start = 638, stop = 642)\n",
      "Completion(text = ' weather', start = 642, stop = 650)\n",
      "Completion(text = ' conditions', start = 650, stop = 661)\n",
      "Completion(text = ' and', start = 661, stop = 665)\n",
      "Completion(text = ' provide', start = 665, stop = 673)\n",
      "Completion(text = ' recommendations', start = 673, stop = 689)\n",
      "Completion(text = ' on', start = 689, stop = 692)\n",
      "Completion(text = ' what', start = 692, stop = 697)\n",
      "Completion(text = ' to', start = 697, stop = 700)\n",
      "Completion(text = ' wear', start = 700, stop = 705)\n",
      "Completion(text = ' based', start = 705, stop = 711)\n",
      "Completion(text = ' on', start = 711, stop = 714)\n",
      "Completion(text = ' the', start = 714, stop = 718)\n",
      "Completion(text = ' forecast', start = 718, stop = 727)\n",
      "Completion(text = 'ed', start = 727, stop = 729)\n",
      "Completion(text = ' weather', start = 729, stop = 737)\n",
      "Completion(text = '.', start = 737, stop = 738)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "prompt = await prompt.complete(model=chat_model, max_tokens=100, stream=print_stream, name='explanation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2281ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(text = 'Based on the user's request to find the best outfit to wear tomorrow, the appropriate tool to use would be Tool C. This tool can analyze the weather conditions and provide recommendations on what to wear based on the forecasted weather.', start = 502, stop = 738)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.completions.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5512a464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/nick/Downloads/orca-mini-v2_7b.ggmlv3.q3_K_S.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 11 (mostly Q3_K - Small)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4603.09 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llama_model = LlamaCpp(model_path=\"/Users/nick/Downloads/orca-mini-v2_7b.ggmlv3.q3_K_S.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d4ab162",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = OptionsConstraint({'A', 'B', 'C'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a86a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_prompt = Prompt(prompt.completions.explanation)+\"\"\"\n",
    "User: Based on this explanation which tool should be chosen?\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "929c8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  6456.59 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1392.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  6456.54 ms /    68 tokens (   94.95 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6461.02 ms\n"
     ]
    }
   ],
   "source": [
    "choice_prompt = await llama_prompt.complete(model=llama_model, constraint=constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bf4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolKinds(Enum):\n",
    "    A = 'A'\n",
    "    B = 'B'\n",
    "    C = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d2fadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def choose_a_tool(prompt, choices_enum: Enum)->ToolKinds:\n",
    "    constraint = OptionsConstraint({e.value for e in choices_enum})\n",
    "    return choices_enum((await prompt.complete(model=llama_model, constraint=constraint)).completions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8acc6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  6456.59 ms\n",
      "llama_print_timings:      sample time =     0.68 ms /     1 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   147.31 ms /     1 runs   (  147.31 ms per token,     6.79 tokens per second)\n",
      "llama_print_timings:       total time =   151.46 ms\n"
     ]
    }
   ],
   "source": [
    "tool_choice: ToolKinds = await choose_a_tool(llama_prompt, ToolKinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dac4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
