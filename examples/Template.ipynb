{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444b8fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d90cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import openai\\n\\nfrom keymaker.models import chatgpt, gpt4, LlamaCpp\\nfrom keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\\nfrom keymaker import Prompt, Completion, CompletionConfig\\n\\nimport json\\n\\nwith open(\\\"./examples/config.json\\\") as f:\\n    openai.api_key = json.loads(f.read())[\\\"OPENAI_API_KEY\\\"]\";\n",
       "                var nbb_formatted_code = \"import openai\\n\\nfrom keymaker.models import chatgpt, gpt4, LlamaCpp\\nfrom keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\\nfrom keymaker import Prompt, Completion, CompletionConfig\\n\\nimport json\\n\\nwith open(\\\"./examples/config.json\\\") as f:\\n    openai.api_key = json.loads(f.read())[\\\"OPENAI_API_KEY\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "from keymaker.models import chatgpt, gpt4, LlamaCpp\n",
    "from keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\n",
    "from keymaker import Prompt, Completion, CompletionConfig\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"./examples/config.json\") as f:\n",
    "    openai.api_key = json.loads(f.read())[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fed5112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"from typing import Optional\\n\\n\\nasync def print_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(repr(completion))\\n\\n\\nasync def yo_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(\\\"YO \\\" + completion)\";\n",
       "                var nbb_formatted_code = \"from typing import Optional\\n\\n\\nasync def print_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(repr(completion))\\n\\n\\nasync def yo_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(\\\"YO \\\" + completion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "async def print_stream(completion: Optional[Completion]):\n",
    "    if completion:\n",
    "        print(repr(completion))\n",
    "\n",
    "\n",
    "async def yo_stream(completion: Optional[Completion]):\n",
    "    if completion:\n",
    "        print(\"YO \" + completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1550ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 11 (mostly Q3_K - Small)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4603.09 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"chat_model = chatgpt()\\n\\nllama_model = LlamaCpp(\\n    model_path=\\\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"chat_model = chatgpt()\\n\\nllama_model = LlamaCpp(\\n    model_path=\\\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_model = chatgpt()\n",
    "\n",
    "llama_model = LlamaCpp(\n",
    "    model_path=\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b99260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from datetime import datetime\\n\\nuser_message = \\\"Hi, my name is Nick.\\\"\";\n",
       "                var nbb_formatted_code = \"from datetime import datetime\\n\\nuser_message = \\\"Hi, my name is Nick.\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "user_message = \"Hi, my name is Nick.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a773eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"my_math_answer = None\\n\\n\\ndef store_my_math(answer):\\n    global my_math_answer\\n    my_math_answer = int(answer)\\n    return \\\"Duh me no know.\\\"\";\n",
       "                var nbb_formatted_code = \"my_math_answer = None\\n\\n\\ndef store_my_math(answer):\\n    global my_math_answer\\n    my_math_answer = int(answer)\\n    return \\\"Duh me no know.\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_math_answer = None\n",
    "\n",
    "\n",
    "def store_my_math(answer):\n",
    "    global my_math_answer\n",
    "    my_math_answer = int(answer)\n",
    "    return \"Duh me no know.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527a7dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YO Nick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1438.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  8470.96 ms /    64 tokens (  132.36 ms per token,     7.56 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8549.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' Of', start=6, stop=9, name=poem, chunk=True, score=0.9606816814575414)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1440.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   719.54 ms /     1 runs   (  719.54 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   722.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.44 ms /     1 runs   (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    83.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' course', start=17, stop=24, name=poem, chunk=True, score=0.9998282827367615)\n",
      "Completion(text=',', start=12, stop=13, name=poem, chunk=True, score=0.7673466883786322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   115.80 ms /     1 runs   (  115.80 ms per token,     8.64 tokens per second)\n",
      "llama_print_timings:       total time =   118.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1443.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    99.42 ms /     1 runs   (   99.42 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =   101.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' I', start=15, stop=17, name=poem, chunk=True, score=0.6681023137503023)\n",
      "Completion(text=''', start=15, stop=16, name=poem, chunk=True, score=0.9940214308062063)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.72 ms /     1 runs   (  102.72 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =   105.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.76 ms /     1 runs   (   85.76 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    87.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1436.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    74.75 ms /     1 runs   (   74.75 ms per token,    13.38 tokens per second)\n",
      "llama_print_timings:       total time =    77.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='d', start=16, stop=17, name=poem, chunk=True, score=0.9795731921419384)\n",
      "Completion(text=' be', start=21, stop=24, name=poem, chunk=True, score=0.9999823360376874)\n",
      "Completion(text=' happy', start=30, stop=36, name=poem, chunk=True, score=0.9991691429354308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.78 ms /     1 runs   (    0.78 ms per token,  1287.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   116.77 ms /     1 runs   (  116.77 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =   119.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1364.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   105.85 ms /     1 runs   (  105.85 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =   108.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' to', start=30, stop=33, name=poem, chunk=True, score=0.9999983151171855)\n",
      "Completion(text=' help', start=37, stop=42, name=poem, chunk=True, score=0.9598538352510234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   116.23 ms /     1 runs   (  116.23 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:       total time =   118.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   148.92 ms /     1 runs   (  148.92 ms per token,     6.72 tokens per second)\n",
      "llama_print_timings:       total time =   151.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='!', start=34, stop=35, name=poem, chunk=True, score=0.6619311494402571)\n",
      "Completion(text=' Here', start=43, stop=48, name=poem, chunk=True, score=0.17240482899440113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1398.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   104.35 ms /     1 runs   (  104.35 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   106.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1440.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.38 ms /     1 runs   (   92.38 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =    94.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=''', start=40, stop=41, name=poem, chunk=True, score=0.9013839631231739)\n",
      "Completion(text='s', start=41, stop=42, name=poem, chunk=True, score=0.9999967136311196)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   101.11 ms /     1 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =   103.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.48 ms /     1 runs   (   96.48 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =    98.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' a', start=44, stop=46, name=poem, chunk=True, score=0.999971451360138)\n",
      "Completion(text=' poem', start=52, stop=57, name=poem, chunk=True, score=0.8673765682502286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   101.54 ms /     1 runs   (  101.54 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =   103.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.98 ms /     1 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   105.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' about', start=59, stop=65, name=poem, chunk=True, score=0.9649511699932131)\n",
      "Completion(text=' P', start=57, stop=59, name=poem, chunk=True, score=0.7591391251658552)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   106.67 ms /     1 runs   (  106.67 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =   108.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.15 ms /     1 runs   (   82.15 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    84.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='and', start=61, stop=64, name=poem, chunk=True, score=0.9665627005133214)\n",
      "Completion(text='aman', start=66, stop=70, name=poem, chunk=True, score=0.999892934280212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    86.81 ms /     1 runs   (   86.81 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    89.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1457.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.30 ms /     1 runs   (   92.30 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =    94.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=':', start=64, stop=65, name=poem, chunk=True, score=0.9994566565324877)\n",
      "Completion(text='\n",
      "', start=65, stop=66, name=poem, chunk=True, score=0.9999934593644355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1438.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.00 ms /     1 runs   (   96.00 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =    98.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.72 ms /     1 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    80.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='P', start=66, stop=67, name=poem, chunk=True, score=0.5981610239758178)\n",
      "Completion(text='and', start=71, stop=74, name=poem, chunk=True, score=0.9933113873196733)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.09 ms /     1 runs   (   92.09 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =    94.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1406.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.17 ms /     1 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    84.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='aman', start=76, stop=80, name=poem, chunk=True, score=0.9999851293397078)\n",
      "Completion(text=',', start=74, stop=75, name=poem, chunk=True, score=0.9844516555149526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    94.17 ms /     1 runs   (   94.17 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =    96.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1434.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    98.49 ms /     1 runs   (   98.49 ms per token,    10.15 tokens per second)\n",
      "llama_print_timings:       total time =   100.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=81, stop=85, name=poem, chunk=True, score=0.6772674020127335)\n",
      "Completion(text=' hero', start=87, stop=92, name=poem, chunk=True, score=0.9907459862582289)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1379.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.80 ms /     1 runs   (   85.80 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    88.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1386.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    84.74 ms /     1 runs   (   84.74 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    86.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' of', start=88, stop=91, name=poem, chunk=True, score=0.9996348775963412)\n",
      "Completion(text=' the', start=93, stop=97, name=poem, chunk=True, score=0.9978855977678759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1390.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   129.24 ms /     1 runs   (  129.24 ms per token,     7.74 tokens per second)\n",
      "llama_print_timings:       total time =   131.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    89.16 ms /     1 runs   (   89.16 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    91.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    76.87 ms /     1 runs   (   76.87 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    79.12 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' sea', start=97, stop=101, name=poem, chunk=True, score=0.5709535923125537)\n",
      "Completion(text=',', start=95, stop=96, name=poem, chunk=True, score=0.6703275553698927)\n",
      "Completion(text='\n",
      "', start=96, stop=97, name=poem, chunk=True, score=0.9999701071057822)\n",
      "Completion(text='With', start=103, stop=107, name=poem, chunk=True, score=0.8368484075106404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.80 ms /     1 runs   (   85.80 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    88.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.40 ms /     1 runs   (   82.40 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    84.63 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' powers', start=113, stop=120, name=poem, chunk=True, score=0.7638546101146654)\n",
      "Completion(text=' beyond', start=120, stop=127, name=poem, chunk=True, score=0.6666689697975614)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.79 ms /     1 runs   (    0.79 ms per token,  1261.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   111.42 ms /     1 runs   (  111.42 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =   113.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.14 ms /     1 runs   (   96.14 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =    98.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   103.21 ms /     1 runs   (  103.21 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =   105.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' your', start=123, stop=128, name=poem, chunk=True, score=0.5592236659628703)\n",
      "Completion(text=' wild', start=128, stop=133, name=poem, chunk=True, score=0.996391580727466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1445.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.33 ms /     1 runs   (   88.33 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    90.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    93.88 ms /     1 runs   (   93.88 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =    96.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='est', start=129, stop=132, name=poem, chunk=True, score=0.9999951805503924)\n",
      "Completion(text=' dream', start=138, stop=144, name=poem, chunk=True, score=0.9853189237085662)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1381.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.10 ms /     1 runs   (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    80.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    97.75 ms /     1 runs   (   97.75 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =   100.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='s', start=134, stop=135, name=poem, chunk=True, score=0.797899381749926)\n",
      "Completion(text=',', start=135, stop=136, name=poem, chunk=True, score=0.9119193277991052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1381.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    83.31 ms /     1 runs   (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    85.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.09 ms /     1 runs   (   88.09 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    90.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='\n",
      "', start=136, stop=137, name=poem, chunk=True, score=0.47799209326142866)\n",
      "Completion(text='He', start=139, stop=141, name=poem, chunk=True, score=0.9219259894324636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   107.34 ms /     1 runs   (  107.34 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =   109.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1369.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.32 ms /     1 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    83.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' can', start=145, stop=149, name=poem, chunk=True, score=0.5958576859196894)\n",
      "Completion(text=' sw', start=147, stop=150, name=poem, chunk=True, score=0.8901131948707545)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1443.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    84.76 ms /     1 runs   (   84.76 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    86.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   101.14 ms /     1 runs   (  101.14 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =   103.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='im', start=148, stop=150, name=poem, chunk=True, score=0.9999775120823572)\n",
      "Completion(text=' with', start=156, stop=161, name=poem, chunk=True, score=0.7515343079162126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   107.62 ms /     1 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =   109.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1369.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    94.40 ms /     1 runs   (   94.40 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =    96.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' grace', start=163, stop=169, name=poem, chunk=True, score=0.2365100300982096)\n",
      "Completion(text=' and', start=165, stop=169, name=poem, chunk=True, score=0.6155520035049101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.31 ms /     1 runs   (   77.31 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    79.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.65 ms /     1 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    84.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.12 ms /     1 runs   (   77.12 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    79.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' speed', start=173, stop=179, name=poem, chunk=True, score=0.8944388095653927)\n",
      "Completion(text=',', start=169, stop=170, name=poem, chunk=True, score=0.9995899647353405)\n",
      "Completion(text='\n",
      "', start=170, stop=171, name=poem, chunk=True, score=0.9999983365111452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   106.43 ms /     1 runs   (  106.43 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   108.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.41 ms /     1 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    80.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='And', start=175, stop=178, name=poem, chunk=True, score=0.9699758928360813)\n",
      "Completion(text=' save', start=182, stop=187, name=poem, chunk=True, score=0.8584132805482192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.02 ms /     1 runs   (   91.02 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    93.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.76 ms /     1 runs   (    0.76 ms per token,  1322.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.67 ms /     1 runs   (   92.67 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =    94.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=185, stop=189, name=poem, chunk=True, score=0.9997566136627343)\n",
      "Completion(text=' day', start=189, stop=193, name=poem, chunk=True, score=0.8632263458390509)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.48 ms /     1 runs   (   82.48 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    84.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.33 ms /     1 runs   (   91.33 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =    93.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' with', start=195, stop=200, name=poem, chunk=True, score=0.974013346033809)\n",
      "Completion(text=' just', start=200, stop=205, name=poem, chunk=True, score=0.39559344911620814)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.49 ms /     1 runs   (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =   104.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.14 ms /     1 runs   (   82.14 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    84.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.92 ms /     1 runs   (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    85.19 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' a', start=199, stop=201, name=poem, chunk=True, score=0.947978812100587)\n",
      "Completion(text=' le', start=203, stop=206, name=poem, chunk=True, score=0.3175152831584154)\n",
      "Completion(text='ap', start=204, stop=206, name=poem, chunk=True, score=0.9998863580991902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.97 ms /     1 runs   (   85.97 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    88.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.31 ms /     1 runs   (   78.31 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    80.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='.', start=204, stop=205, name=poem, chunk=True, score=0.9953161118116055)\n",
      "Completion(text='\n",
      "', start=205, stop=206, name=poem, chunk=True, score=0.9999974357439021)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   100.63 ms /     1 runs   (  100.63 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =   102.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.97 ms /     1 runs   (   90.97 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    93.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='H', start=206, stop=207, name=poem, chunk=True, score=0.7900509514743014)\n",
      "Completion(text='is', start=209, stop=211, name=poem, chunk=True, score=0.9999842025893715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.79 ms /     1 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    84.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1438.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.74 ms /     1 runs   (   90.74 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =    93.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' f', start=211, stop=213, name=poem, chunk=True, score=0.4585904311176187)\n",
      "Completion(text='li', start=213, stop=215, name=poem, chunk=True, score=0.9998558075418772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    94.02 ms /     1 runs   (   94.02 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =    96.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.98 ms /     1 runs   (   78.98 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    81.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='ppers', start=221, stop=226, name=poem, chunk=True, score=0.9848502577395569)\n",
      "Completion(text=' are', start=224, stop=228, name=poem, chunk=True, score=0.47769251593941314)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.03 ms /     1 runs   (   91.03 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =    93.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.54 ms /     1 runs   (   90.54 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    92.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    75.43 ms /     1 runs   (   75.43 ms per token,    13.26 tokens per second)\n",
      "llama_print_timings:       total time =    77.68 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' strong', start=234, stop=241, name=poem, chunk=True, score=0.9970764172111679)\n",
      "Completion(text=' and', start=235, stop=239, name=poem, chunk=True, score=0.9502334767700358)\n",
      "Completion(text=' long', start=241, stop=246, name=poem, chunk=True, score=0.1742353424723524)\n",
      "Completion(text=',', start=238, stop=239, name=poem, chunk=True, score=0.9999922140211345)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1438.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    89.41 ms /     1 runs   (   89.41 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    91.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.10 ms /     1 runs   (   91.10 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =    93.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.73 ms /     1 runs   (   88.73 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    91.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.10 ms /     1 runs   (   77.10 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    79.35 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='\n",
      "', start=239, stop=240, name=poem, chunk=True, score=0.9999989735321752)\n",
      "Completion(text='And', start=244, stop=247, name=poem, chunk=True, score=0.9354344416733137)\n",
      "Completion(text=' his', start=249, stop=253, name=poem, chunk=True, score=0.47578098138283537)\n",
      "Completion(text=' tail', start=255, stop=260, name=poem, chunk=True, score=0.36862531072941596)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1385.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    94.21 ms /     1 runs   (   94.21 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =    96.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1396.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    86.48 ms /     1 runs   (   86.48 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    89.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    99.45 ms /     1 runs   (   99.45 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =   101.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' is', start=256, stop=259, name=poem, chunk=True, score=0.5004371381418592)\n",
      "Completion(text=' quick', start=265, stop=271, name=poem, chunk=True, score=0.39952719076858595)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   109.46 ms /     1 runs   (  109.46 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =   111.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.80 ms /     1 runs   (   77.80 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    80.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    86.32 ms /     1 runs   (   86.32 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    88.62 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' and', start=267, stop=271, name=poem, chunk=True, score=0.9972340550865543)\n",
      "Completion(text=' ag', start=269, stop=272, name=poem, chunk=True, score=0.190103923012906)\n",
      "Completion(text='ile', start=272, stop=275, name=poem, chunk=True, score=0.999980542476297)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    79.09 ms /     1 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    81.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.78 ms /     1 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    85.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=',', start=271, stop=272, name=poem, chunk=True, score=0.9989297527919079)\n",
      "Completion(text='\n",
      "', start=272, stop=273, name=poem, chunk=True, score=0.9999949026740055)\n",
      "Completion(text='He', start=275, stop=277, name=poem, chunk=True, score=0.9961699750117315)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    75.77 ms /     1 runs   (   75.77 ms per token,    13.20 tokens per second)\n",
      "llama_print_timings:       total time =    78.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.35 ms /     1 runs   (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    84.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.79 ms /     1 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    84.09 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=''', start=275, stop=276, name=poem, chunk=True, score=0.18795396062346953)\n",
      "Completion(text='s', start=276, stop=277, name=poem, chunk=True, score=0.977422329142375)\n",
      "Completion(text=' got', start=283, stop=287, name=poem, chunk=True, score=0.1348452733866405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.83 ms /     1 runs   (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    84.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.42 ms /     1 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    84.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=287, stop=291, name=poem, chunk=True, score=0.661577971143812)\n",
      "Completion(text=' power', start=295, stop=301, name=poem, chunk=True, score=0.5624376098753544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.24 ms /     1 runs   (   91.24 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =    93.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    86.86 ms /     1 runs   (   86.86 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    89.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' to', start=295, stop=298, name=poem, chunk=True, score=0.8642006757339084)\n",
      "Completion(text=' t', start=296, stop=298, name=poem, chunk=True, score=0.19381398886174822)\n",
      "Completion(text='ame', start=300, stop=303, name=poem, chunk=True, score=0.9905099350708941)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    80.19 ms /     1 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    82.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.78 ms /     1 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    85.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    95.69 ms /     1 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =    98.00 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=305, stop=309, name=poem, chunk=True, score=0.988357659597173)\n",
      "Completion(text=' ocean', start=313, stop=319, name=poem, chunk=True, score=0.25728725090118537)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.54 ms /     1 runs   (   96.54 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =    98.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    89.97 ms /     1 runs   (   89.97 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    92.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   121.25 ms /     1 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
      "llama_print_timings:       total time =   123.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=''', start=309, stop=310, name=poem, chunk=True, score=0.6233806045055506)\n",
      "Completion(text='s', start=310, stop=311, name=poem, chunk=True, score=0.9999898317807064)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1394.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.88 ms /     1 runs   (   82.88 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    85.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.81 ms /     1 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    88.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' ro', start=315, stop=318, name=poem, chunk=True, score=0.8135576951150612)\n",
      "Completion(text='ar', start=316, stop=318, name=poem, chunk=True, score=0.9999640404461694)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    80.82 ms /     1 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    83.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1406.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.13 ms /     1 runs   (   88.13 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    90.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.29 ms /     1 runs   (   77.29 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    79.63 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=',', start=316, stop=317, name=poem, chunk=True, score=0.9998231598623539)\n",
      "Completion(text='\n",
      "', start=317, stop=318, name=poem, chunk=True, score=0.9999988424999265)\n",
      "Completion(text='And', start=322, stop=325, name=poem, chunk=True, score=0.9998974300385144)\n",
      "Completion(text=' bring', start=331, stop=337, name=poem, chunk=True, score=0.403309977032479)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    95.73 ms /     1 runs   (   95.73 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =    98.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1396.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    99.35 ms /     1 runs   (   99.35 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =   101.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.84 ms /     1 runs   (   96.84 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =    99.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' peace', start=337, stop=343, name=poem, chunk=True, score=0.819693554251187)\n",
      "Completion(text=' to', start=337, stop=340, name=poem, chunk=True, score=0.9871069325794892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   106.87 ms /     1 runs   (  106.87 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   109.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   113.05 ms /     1 runs   (  113.05 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =   115.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=342, stop=346, name=poem, chunk=True, score=0.7984324548121992)\n",
      "Completion(text=' trouble', start=354, stop=362, name=poem, chunk=True, score=0.5255922297906622)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   101.48 ms /     1 runs   (  101.48 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =   103.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1390.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    87.94 ms /     1 runs   (   87.94 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    90.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1398.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.31 ms /     1 runs   (   90.31 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    92.61 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='d', start=348, stop=349, name=poem, chunk=True, score=0.9997821075546179)\n",
      "Completion(text=' sea', start=355, stop=359, name=poem, chunk=True, score=0.2232437872225111)\n",
      "Completion(text=' floor', start=363, stop=369, name=poem, chunk=True, score=0.22017906408039944)\n",
      "Completion(text='.', start=359, stop=360, name=poem, chunk=True, score=0.9999710870726389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1364.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   117.56 ms /     1 runs   (  117.56 ms per token,     8.51 tokens per second)\n",
      "llama_print_timings:       total time =   120.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.42 ms /     1 runs   (  102.42 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =   104.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1388.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    89.61 ms /     1 runs   (   89.61 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    91.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='\n",
      "', start=360, stop=361, name=poem, chunk=True, score=0.9999939834439555)\n",
      "Completion(text='P', start=361, stop=362, name=poem, chunk=True, score=0.3735986210953788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   117.79 ms /     1 runs   (  117.79 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =   120.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   103.40 ms /     1 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =   105.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='and', start=366, stop=369, name=poem, chunk=True, score=0.9999128872746533)\n",
      "Completion(text='aman', start=371, stop=375, name=poem, chunk=True, score=0.9999953703090807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1406.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.98 ms /     1 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   105.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.78 ms /     1 runs   (   92.78 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    95.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=',', start=369, stop=370, name=poem, chunk=True, score=0.9632640414706807)\n",
      "Completion(text=' the', start=376, stop=380, name=poem, chunk=True, score=0.9926212748906719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.89 ms /     1 runs   (   90.89 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    93.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    98.03 ms /     1 runs   (   98.03 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =   100.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' hero', start=382, stop=387, name=poem, chunk=True, score=0.5508709661333344)\n",
      "Completion(text=' of', start=383, stop=386, name=poem, chunk=True, score=0.9979527766126409)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1396.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    80.60 ms /     1 runs   (   80.60 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    82.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.00 ms /     1 runs   (   90.00 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    92.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=388, stop=392, name=poem, chunk=True, score=0.9979235956069871)\n",
      "Completion(text=' deep', start=394, stop=399, name=poem, chunk=True, score=0.7975316316588564)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.37 ms /     1 runs   (   88.37 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    90.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    93.24 ms /     1 runs   (   93.24 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =    95.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=',', start=391, stop=392, name=poem, chunk=True, score=0.9987663242680908)\n",
      "Completion(text='\n",
      "', start=392, stop=393, name=poem, chunk=True, score=0.9999996183636992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1396.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   106.42 ms /     1 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   108.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   119.04 ms /     1 runs   (  119.04 ms per token,     8.40 tokens per second)\n",
      "llama_print_timings:       total time =   121.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='A', start=393, stop=394, name=poem, chunk=True, score=0.4215715334820434)\n",
      "Completion(text=' symbol', start=406, stop=413, name=poem, chunk=True, score=0.557477763387377)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1434.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   105.41 ms /     1 runs   (  105.41 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   107.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    86.94 ms /     1 runs   (   86.94 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    89.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' of', start=405, stop=408, name=poem, chunk=True, score=0.9999703540037039)\n",
      "Completion(text=' hope', start=412, stop=417, name=poem, chunk=True, score=0.9702484311700461)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1371.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.06 ms /     1 runs   (   92.06 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =    94.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   107.95 ms /     1 runs   (  107.95 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =   110.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' and', start=415, stop=419, name=poem, chunk=True, score=0.8626657808357646)\n",
      "Completion(text=' courage', start=427, stop=435, name=poem, chunk=True, score=0.7754720443189426)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.73 ms /     1 runs   (    0.73 ms per token,  1364.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    80.46 ms /     1 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    82.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1426.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    76.64 ms /     1 runs   (   76.64 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:       total time =    78.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.85 ms /     1 runs   (   85.85 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    88.18 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' to', start=425, stop=428, name=poem, chunk=True, score=0.4456001539300289)\n",
      "Completion(text=' keep', start=432, stop=437, name=poem, chunk=True, score=0.9923841723799348)\n",
      "Completion(text=',', start=429, stop=430, name=poem, chunk=True, score=0.9186027066778224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.43 ms /     1 runs   (   96.43 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =    98.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='\n",
      "', start=430, stop=431, name=poem, chunk=True, score=0.9999998188391409)\n",
      "Completion(text='He', start=433, stop=435, name=poem, chunk=True, score=0.9335427883595669)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.74 ms /     1 runs   (    0.74 ms per token,  1353.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   120.11 ms /     1 runs   (  120.11 ms per token,     8.33 tokens per second)\n",
      "llama_print_timings:       total time =   122.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1406.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   108.83 ms /     1 runs   (  108.83 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =   111.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' gu', start=437, stop=440, name=poem, chunk=True, score=0.18860434370765894)\n",
      "Completion(text='ards', start=442, stop=446, name=poem, chunk=True, score=0.9349154658305878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1443.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   147.97 ms /     1 runs   (  147.97 ms per token,     6.76 tokens per second)\n",
      "llama_print_timings:       total time =   150.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1398.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    97.53 ms /     1 runs   (   97.53 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =    99.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=446, stop=450, name=poem, chunk=True, score=0.9979481481836218)\n",
      "Completion(text=' ocean', start=454, stop=460, name=poem, chunk=True, score=0.5479212948902736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   126.76 ms /     1 runs   (  126.76 ms per token,     7.89 tokens per second)\n",
      "llama_print_timings:       total time =   129.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   111.03 ms /     1 runs   (  111.03 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =   113.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=''', start=450, stop=451, name=poem, chunk=True, score=0.9289249102476477)\n",
      "Completion(text='s', start=451, stop=452, name=poem, chunk=True, score=0.9999952905423418)\n",
      "Completion(text=' secre', start=462, stop=468, name=poem, chunk=True, score=0.5288945330622713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    89.45 ms /     1 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    91.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1388.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    75.23 ms /     1 runs   (   75.23 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:       total time =    77.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    80.49 ms /     1 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    82.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='ts', start=460, stop=462, name=poem, chunk=True, score=0.9999655792405526)\n",
      "Completion(text=' with', start=468, stop=473, name=poem, chunk=True, score=0.7824532800432192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    88.57 ms /     1 runs   (   88.57 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    90.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.69 ms /     1 runs   (    0.69 ms per token,  1455.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    99.44 ms /     1 runs   (   99.44 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =   101.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' a', start=467, stop=469, name=poem, chunk=True, score=0.6193824511910933)\n",
      "Completion(text=' gr', start=471, stop=474, name=poem, chunk=True, score=0.7662521639890367)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   112.28 ms /     1 runs   (  112.28 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =   114.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1408.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   111.84 ms /     1 runs   (  111.84 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =   114.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='in', start=472, stop=474, name=poem, chunk=True, score=0.9999469098177324)\n",
      "Completion(text=',', start=472, stop=473, name=poem, chunk=True, score=0.9999317394798437)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    98.07 ms /     1 runs   (   98.07 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =   100.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   110.22 ms /     1 runs   (  110.22 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   112.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='\n",
      "', start=473, stop=474, name=poem, chunk=True, score=0.9999996857941088)\n",
      "Completion(text='And', start=478, stop=481, name=poem, chunk=True, score=0.999918462551667)\n",
      "Completion(text=' keeps', start=487, stop=493, name=poem, chunk=True, score=0.2911310998419507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.78 ms /     1 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    85.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.22 ms /     1 runs   (   78.22 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    80.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.16 ms /     1 runs   (   91.16 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =    93.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    82.56 ms /     1 runs   (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    84.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=489, stop=493, name=poem, chunk=True, score=0.9657231994956219)\n",
      "Completion(text=' sea', start=493, stop=497, name=poem, chunk=True, score=0.8311943211986679)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    92.14 ms /     1 runs   (   92.14 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =    94.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   114.00 ms /     1 runs   (  114.00 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   116.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' cre', start=497, stop=501, name=poem, chunk=True, score=0.5107371429734818)\n",
      "Completion(text='atures', start=505, stop=511, name=poem, chunk=True, score=0.9999963345699282)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.00 ms /     1 runs   (   90.00 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    92.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   111.08 ms /     1 runs   (  111.08 ms per token,     9.00 tokens per second)\n",
      "llama_print_timings:       total time =   113.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' safe', start=509, stop=514, name=poem, chunk=True, score=0.5174053108625524)\n",
      "Completion(text=' within', start=518, stop=525, name=poem, chunk=True, score=0.9581553943336764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1404.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    95.39 ms /     1 runs   (   95.39 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =    97.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   109.81 ms /     1 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =   112.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='.', start=513, stop=514, name=poem, chunk=True, score=0.9999826932068075)\n",
      "Completion(text='\n",
      "', start=514, stop=515, name=poem, chunk=True, score=0.9985465660242111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1434.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   123.06 ms /     1 runs   (  123.06 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =   125.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1434.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   100.72 ms /     1 runs   (  100.72 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =   103.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='So', start=517, stop=519, name=poem, chunk=True, score=0.6169683029125373)\n",
      "Completion(text=' if', start=521, stop=524, name=poem, chunk=True, score=0.6551588706070701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    96.84 ms /     1 runs   (   96.84 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =    99.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.40 ms /     1 runs   (   90.40 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =    92.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' you', start=526, stop=530, name=poem, chunk=True, score=0.9984991897299204)\n",
      "Completion(text=' ever', start=532, stop=537, name=poem, chunk=True, score=0.15019244280136024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.34 ms /     1 runs   (   78.34 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    80.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    87.80 ms /     1 runs   (   87.80 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    90.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    83.92 ms /     1 runs   (   83.92 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    86.23 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' find', start=537, stop=542, name=poem, chunk=True, score=0.5655917391424082)\n",
      "Completion(text=' yourself', start=550, stop=559, name=poem, chunk=True, score=0.9998682869181589)\n",
      "Completion(text=' in', start=547, stop=550, name=poem, chunk=True, score=0.9831675471199511)\n",
      "Completion(text=' need', start=554, stop=559, name=poem, chunk=True, score=0.2960303904988863)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    91.45 ms /     1 runs   (   91.45 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =    93.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.00 ms /     1 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    83.35 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=',', start=551, stop=552, name=poem, chunk=True, score=0.9999022273682255)\n",
      "Completion(text='\n",
      "', start=552, stop=553, name=poem, chunk=True, score=0.9999997596759758)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.72 ms /     1 runs   (    0.72 ms per token,  1394.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   105.27 ms /     1 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   107.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   107.73 ms /     1 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   110.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    79.05 ms /     1 runs   (   79.05 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    81.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='Just', start=559, stop=563, name=poem, chunk=True, score=0.9099587417937782)\n",
      "Completion(text=' call', start=565, stop=570, name=poem, chunk=True, score=0.9967651498087168)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    90.79 ms /     1 runs   (   90.79 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    93.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   127.59 ms /     1 runs   (  127.59 ms per token,     7.84 tokens per second)\n",
      "llama_print_timings:       total time =   129.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' on', start=566, stop=569, name=poem, chunk=True, score=0.8151199159215076)\n",
      "Completion(text=' P', start=567, stop=569, name=poem, chunk=True, score=0.9999419928012545)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    98.35 ms /     1 runs   (   98.35 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =   100.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    79.39 ms /     1 runs   (   79.39 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    81.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1418.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    77.52 ms /     1 runs   (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    79.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='and', start=571, stop=574, name=poem, chunk=True, score=0.9999915992936588)\n",
      "Completion(text='aman', start=576, stop=580, name=poem, chunk=True, score=0.9999951055048404)\n",
      "Completion(text=',', start=574, stop=575, name=poem, chunk=True, score=0.8326928476745796)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1420.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    81.62 ms /     1 runs   (   81.62 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    84.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    85.08 ms /     1 runs   (   85.08 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    87.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    78.35 ms /     1 runs   (   78.35 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    80.73 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' the', start=581, stop=585, name=poem, chunk=True, score=0.6019521645802184)\n",
      "Completion(text=' hero', start=587, stop=592, name=poem, chunk=True, score=0.896433164173831)\n",
      "Completion(text=' indeed', start=596, stop=603, name=poem, chunk=True, score=0.46265872949868814)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1412.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   102.31 ms /     1 runs   (  102.31 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =   104.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='!', start=591, stop=592, name=poem, chunk=True, score=0.20164835957387073)\n",
      "Completion(text='\n",
      "', start=592, stop=593, name=poem, chunk=True, score=0.9840566791160391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.71 ms /     1 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    93.34 ms /     1 runs   (   93.34 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =    95.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =    79.02 ms /     1 runs   (   79.02 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    81.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='User', start=599, stop=603, name=poem, chunk=True, score=0.44202450083691575)\n",
      "Completion(text='1', start=2, stop=3, name=math, chunk=True, score=0.9999913689096965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8471.13 ms\n",
      "llama_print_timings:      sample time =     0.70 ms /     1 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1767.31 ms /    25 tokens (   70.69 ms per token,    14.15 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1800.61 ms\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# default model, stream and max_tokens for all completions\\nprompt = Prompt(\\n    \\\"\\\"\\\"Time: {time}\\nUser: {user_msg}\\nAssistant: Hello, {}{punctuation}\\nUser: Can you write me a poem about a superhero named pandaman?\\nAssistant:{poem}\\nUser: What is 10+5?\\nAssistant: The answer is 10+5={math}\\n\\\"\\\"\\\",\\n    chat_model,\\n    stream=print_stream,\\n    max_tokens=25,\\n)\\n\\nfilled_in = await prompt.format(\\n    # custom constraint\\n    CompletionConfig(constraint=OptionsConstraint({\\\"Sam\\\", \\\"Nick\\\"}), stream=yo_stream),\\n    # can do formatting just like a regular python string\\n    punctuation=\\\"!\\\",\\n    user_msg=user_message,\\n    time=datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\"),\\n    poem=CompletionConfig(\\n        llama_model, max_tokens=250, constraint=StopsConstraint(\\\"User|Assistant\\\")\\n    ),\\n    math=CompletionConfig(\\n        llama_model, constraint=RegexConstraint(\\\"[0-9]+\\\"), map_fn=store_my_math\\n    ),\\n)\";\n",
       "                var nbb_formatted_code = \"# default model, stream and max_tokens for all completions\\nprompt = Prompt(\\n    \\\"\\\"\\\"Time: {time}\\nUser: {user_msg}\\nAssistant: Hello, {}{punctuation}\\nUser: Can you write me a poem about a superhero named pandaman?\\nAssistant:{poem}\\nUser: What is 10+5?\\nAssistant: The answer is 10+5={math}\\n\\\"\\\"\\\",\\n    chat_model,\\n    stream=print_stream,\\n    max_tokens=25,\\n)\\n\\nfilled_in = await prompt.format(\\n    # custom constraint\\n    CompletionConfig(constraint=OptionsConstraint({\\\"Sam\\\", \\\"Nick\\\"}), stream=yo_stream),\\n    # can do formatting just like a regular python string\\n    punctuation=\\\"!\\\",\\n    user_msg=user_message,\\n    time=datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\"),\\n    poem=CompletionConfig(\\n        llama_model, max_tokens=250, constraint=StopsConstraint(\\\"User|Assistant\\\")\\n    ),\\n    math=CompletionConfig(\\n        llama_model, constraint=RegexConstraint(\\\"[0-9]+\\\"), map_fn=store_my_math\\n    ),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default model, stream and max_tokens for all completions\n",
    "prompt = Prompt(\n",
    "    \"\"\"Time: {time}\n",
    "User: {user_msg}\n",
    "Assistant: Hello, {}{punctuation}\n",
    "User: Can you write me a poem about a superhero named pandaman?\n",
    "Assistant:{poem}\n",
    "User: What is 10+5?\n",
    "Assistant: The answer is 10+5={math}\n",
    "\"\"\",\n",
    "    chat_model,\n",
    "    stream=print_stream,\n",
    "    max_tokens=25,\n",
    ")\n",
    "\n",
    "filled_in = await prompt.format(\n",
    "    # custom constraint\n",
    "    CompletionConfig(constraint=OptionsConstraint({\"Sam\", \"Nick\"}), stream=yo_stream),\n",
    "    # can do formatting just like a regular python string\n",
    "    punctuation=\"!\",\n",
    "    user_msg=user_message,\n",
    "    time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    poem=CompletionConfig(\n",
    "        llama_model, max_tokens=250, constraint=StopsConstraint(\"User|Assistant\")\n",
    "    ),\n",
    "    math=CompletionConfig(\n",
    "        llama_model, constraint=RegexConstraint(\"[0-9]+\"), map_fn=store_my_math\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef5faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt('Time: 2023-07-21 21:48:06\n",
       "User: Hi, my name is Nick.\n",
       "Assistant: Hello, Nick!\n",
       "User: Can you write me a poem about a superhero named pandaman?\n",
       "Assistant:User\n",
       "User: What is 10+5?\n",
       "Assistant: The answer is 10+5=Duh me no know.\n",
       "')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"filled_in\";\n",
       "                var nbb_formatted_code = \"filled_in\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fee8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(text='User', start=151, stop=155, name=poem, chunk=False, score=4.091912637842387e-25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"filled_in.completions.poem\";\n",
       "                var nbb_formatted_code = \"filled_in.completions.poem\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in.completions.poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328ed4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Duh me no know.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"filled_in.completions.math\";\n",
       "                var nbb_formatted_code = \"filled_in.completions.math\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in.completions.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d63cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
