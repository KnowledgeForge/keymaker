{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c5755b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9ac19",
   "metadata": {},
   "source": [
    "# First, some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499165b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"from datetime import datetime\\nfrom typing import Optional\\nimport openai\\n\\n# There are a variety of models available in Keymaker.\\n# Some are aliased such as gpt4 and chatgpt\\nfrom keymaker.models import chatgpt, LlamaCpp  # , gpt4, OpenAICompletion, OpenAIChat\\n\\n# There are a variety of constraints as well.\\n# These are just a few of the most common.\\nfrom keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\\n\\n# Finally, the core components of Keymaker\\nfrom keymaker import Prompt, Completion, CompletionConfig\";\n",
       "                var nbb_formatted_code = \"from datetime import datetime\\nfrom typing import Optional\\nimport openai\\n\\n# There are a variety of models available in Keymaker.\\n# Some are aliased such as gpt4 and chatgpt\\nfrom keymaker.models import chatgpt, LlamaCpp  # , gpt4, OpenAICompletion, OpenAIChat\\n\\n# There are a variety of constraints as well.\\n# These are just a few of the most common.\\nfrom keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\\n\\n# Finally, the core components of Keymaker\\nfrom keymaker import Prompt, Completion, CompletionConfig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import openai\n",
    "\n",
    "# There are a variety of models available in Keymaker.\n",
    "# Some are aliased such as gpt4 and chatgpt\n",
    "from keymaker.models import chatgpt, LlamaCpp  # , gpt4, OpenAICompletion, OpenAIChat\n",
    "\n",
    "# There are a variety of constraints as well.\n",
    "# These are just a few of the most common.\n",
    "from keymaker.constraints import RegexConstraint, OptionsConstraint, StopsConstraint\n",
    "\n",
    "# Finally, the core components of Keymaker\n",
    "from keymaker import Prompt, Completion, CompletionConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034ddc7",
   "metadata": {},
   "source": [
    "# Part of this demo showcases Keymaker's ability to leverage OpenAI models.\n",
    "You can modify this as needed including swapping the model, but if you follow this example directly, load an api key however you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262c7f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import json\\n\\nwith open(\\\"./config.json\\\") as f:\\n    openai.api_key = json.loads(f.read())[\\\"OPENAI_API_KEY\\\"]\";\n",
       "                var nbb_formatted_code = \"import json\\n\\nwith open(\\\"./config.json\\\") as f:\\n    openai.api_key = json.loads(f.read())[\\\"OPENAI_API_KEY\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./config.json\") as f:\n",
    "    openai.api_key = json.loads(f.read())[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf8163",
   "metadata": {},
   "source": [
    "# For example's sake, we will can just create two streams that do some sort of printing\n",
    "In reality, this could feed SSE or a websocket. Of course, streaming is optional as most everything in Keymaker is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f071761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"async def print_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(repr(completion))\\n\\n\\nasync def yo_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(\\\"YO \\\" + completion)\";\n",
       "                var nbb_formatted_code = \"async def print_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(repr(completion))\\n\\n\\nasync def yo_stream(completion: Optional[Completion]):\\n    if completion:\\n        print(\\\"YO \\\" + completion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def print_stream(completion: Optional[Completion]):\n",
    "    if completion:\n",
    "        print(repr(completion))\n",
    "\n",
    "\n",
    "async def yo_stream(completion: Optional[Completion]):\n",
    "    if completion:\n",
    "        print(\"YO \" + completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9408bc",
   "metadata": {},
   "source": [
    "# Let's establish the models upfront for the example\n",
    "We will use the alias for ChatGPT. There are parameters we can set for Models, but we will just use the defaults here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "004312a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 11 (mostly Q3_K - Small)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4603.09 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"chat_model = chatgpt()\\n\\nllama_model = LlamaCpp(\\n    model_path=\\\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\\\",\\n    llama_kwargs={\\\"verbose\\\": False},\\n)\";\n",
       "                var nbb_formatted_code = \"chat_model = chatgpt()\\n\\nllama_model = LlamaCpp(\\n    model_path=\\\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\\\",\\n    llama_kwargs={\\\"verbose\\\": False},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_model = chatgpt()\n",
    "\n",
    "llama_model = LlamaCpp(\n",
    "    model_path=\"/Users/nick/Downloads/llama-2-7b-chat.ggmlv3.q3_K_S.bin\",\n",
    "    llama_kwargs={\"verbose\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e8770",
   "metadata": {},
   "source": [
    "# These are some fun things we can just plug into our prompt at any time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571d1bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# A friendly use message stored in a variable\\nuser_message = \\\"Hi, my name is Nick.\\\"\\n\\n# This shows how you can do anything you ever would with a `map_fn` function you intend to use with Keymaker\\nmy_math_answer = None\\n\\n\\ndef store_my_math(answer):\\n    global my_math_answer\\n    my_math_answer = int(answer)\\n    if my_math_answer != 15:\\n        return \\\"Duh me no know.\\\"\\n    return 15\\n\\n\\n# Again, we can do anything with a `map_fn`\\ndef my_log_function(some_completion):\\n    import logging\\n\\n    # Set up logging configuration\\n    logging.basicConfig(filename=\\\"my_log_file.log\\\", level=logging.INFO)\\n\\n    # Log the completion info\\n    logging.info(f\\\"Some completion: {some_completion}\\\")\\n\\n    return some_completion\";\n",
       "                var nbb_formatted_code = \"# A friendly use message stored in a variable\\nuser_message = \\\"Hi, my name is Nick.\\\"\\n\\n# This shows how you can do anything you ever would with a `map_fn` function you intend to use with Keymaker\\nmy_math_answer = None\\n\\n\\ndef store_my_math(answer):\\n    global my_math_answer\\n    my_math_answer = int(answer)\\n    if my_math_answer != 15:\\n        return \\\"Duh me no know.\\\"\\n    return 15\\n\\n\\n# Again, we can do anything with a `map_fn`\\ndef my_log_function(some_completion):\\n    import logging\\n\\n    # Set up logging configuration\\n    logging.basicConfig(filename=\\\"my_log_file.log\\\", level=logging.INFO)\\n\\n    # Log the completion info\\n    logging.info(f\\\"Some completion: {some_completion}\\\")\\n\\n    return some_completion\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A friendly use message stored in a variable\n",
    "user_message = \"Hi, my name is Nick.\"\n",
    "\n",
    "# This shows how you can do anything you ever would with a `map_fn` function you intend to use with Keymaker\n",
    "my_math_answer = None\n",
    "\n",
    "\n",
    "def store_my_math(answer):\n",
    "    global my_math_answer\n",
    "    my_math_answer = int(answer)\n",
    "    if my_math_answer != 15:\n",
    "        return \"Duh me no know.\"\n",
    "    return 15\n",
    "\n",
    "\n",
    "# Again, we can do anything with a `map_fn`\n",
    "def my_log_function(some_completion):\n",
    "    import logging\n",
    "\n",
    "    # Set up logging configuration\n",
    "    logging.basicConfig(filename=\"my_log_file.log\", level=logging.INFO)\n",
    "\n",
    "    # Log the completion info\n",
    "    logging.info(f\"Some completion: {some_completion}\")\n",
    "\n",
    "    return some_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4114d5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# These are the values you can specify for things related to generating completions\\n# e.g. Prompt defaults and CompletionConfig parameters:\\n#\\n# The model to use for completion\\n#     model: Optional[Model] = None\\n#\\n# An optional constraint to restrict model output\\n#     constraint: Optional[Constraint] = None\\n#\\n# An optional name to label the completion in the prompt\\n#     name: Optional[str] = None\\n#\\n# The maximum number of tokens that can be generated in the completion\\n#     max_tokens: Optional[int] = None\\n#\\n# Any decoding parameters e.g. temperature, top_p, strategy (Greedy, Sample). Defaults to a greedy decoder with the OpenAI default temp and top_p\\n#     decoder: Optional[Decoder] = None\\n#\\n# An async function that completion chunks (tokens) will be passed to as generated. Once done, a None will be sent\\n#     stream: Optional[Callable[[Optional['Completion']], Awaitable[Any]]] = None\\n#\\n# A function to run on a completion once it is completed. The output must be castable to a string and will be added to the prompt in place of the completion given.\\n#     map_fn: Callable[[Completion], Stringable] = noop\\n#\\n# How long to wait for model response before giving up\\n#     timeout: float = 10.0\\n#\\n# Whether or not to truncate the length of the prompt prior to generation to avoid overflow and potential error of the model\\n#     truncate: bool = False\\n#\\n# Whether to eagerly generate tokens and then test whether they abide by the constrain.\\n# This depends on parameters set at the model level such as `sample_chunk_size` on OpenAIChat models.\\n# None is 'auto' and will allow Keymaker to decide if this is necessary on its own\\n#     try_first: Optional[bool] = None\";\n",
       "                var nbb_formatted_code = \"# These are the values you can specify for things related to generating completions\\n# e.g. Prompt defaults and CompletionConfig parameters:\\n#\\n# The model to use for completion\\n#     model: Optional[Model] = None\\n#\\n# An optional constraint to restrict model output\\n#     constraint: Optional[Constraint] = None\\n#\\n# An optional name to label the completion in the prompt\\n#     name: Optional[str] = None\\n#\\n# The maximum number of tokens that can be generated in the completion\\n#     max_tokens: Optional[int] = None\\n#\\n# Any decoding parameters e.g. temperature, top_p, strategy (Greedy, Sample). Defaults to a greedy decoder with the OpenAI default temp and top_p\\n#     decoder: Optional[Decoder] = None\\n#\\n# An async function that completion chunks (tokens) will be passed to as generated. Once done, a None will be sent\\n#     stream: Optional[Callable[[Optional['Completion']], Awaitable[Any]]] = None\\n#\\n# A function to run on a completion once it is completed. The output must be castable to a string and will be added to the prompt in place of the completion given.\\n#     map_fn: Callable[[Completion], Stringable] = noop\\n#\\n# How long to wait for model response before giving up\\n#     timeout: float = 10.0\\n#\\n# Whether or not to truncate the length of the prompt prior to generation to avoid overflow and potential error of the model\\n#     truncate: bool = False\\n#\\n# Whether to eagerly generate tokens and then test whether they abide by the constrain.\\n# This depends on parameters set at the model level such as `sample_chunk_size` on OpenAIChat models.\\n# None is 'auto' and will allow Keymaker to decide if this is necessary on its own\\n#     try_first: Optional[bool] = None\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# These are the values you can specify for things related to generating completions\n",
    "# e.g. Prompt defaults and CompletionConfig parameters:\n",
    "#\n",
    "# The model to use for completion\n",
    "#     model: Optional[Model] = None\n",
    "#\n",
    "# An optional constraint to restrict model output\n",
    "#     constraint: Optional[Constraint] = None\n",
    "#\n",
    "# An optional name to label the completion in the prompt\n",
    "#     name: Optional[str] = None\n",
    "#\n",
    "# The maximum number of tokens that can be generated in the completion\n",
    "#     max_tokens: Optional[int] = None\n",
    "#\n",
    "# Any decoding parameters e.g. temperature, top_p, strategy (Greedy, Sample). Defaults to a greedy decoder with the OpenAI default temp and top_p\n",
    "#     decoder: Optional[Decoder] = None\n",
    "#\n",
    "# An async function that completion chunks (tokens) will be passed to as generated. Once done, a None will be sent\n",
    "#     stream: Optional[Callable[[Optional['Completion']], Awaitable[Any]]] = None\n",
    "#\n",
    "# A function to run on a completion once it is completed. The output must be castable to a string and will be added to the prompt in place of the completion given.\n",
    "#     map_fn: Callable[[Completion], Stringable] = noop\n",
    "#\n",
    "# How long to wait for model response before giving up\n",
    "#     timeout: float = 10.0\n",
    "#\n",
    "# Whether or not to truncate the length of the prompt prior to generation to avoid overflow and potential error of the model\n",
    "#     truncate: bool = False\n",
    "#\n",
    "# Whether to eagerly generate tokens and then test whether they abide by the constrain.\n",
    "# This depends on parameters set at the model level such as `sample_chunk_size` on OpenAIChat models.\n",
    "# None is 'auto' and will allow Keymaker to decide if this is necessary on its own\n",
    "#     try_first: Optional[bool] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91661d",
   "metadata": {},
   "source": [
    "# Here, we create a prompt with format parameters as you would expect in regular python strings.\n",
    "`{}` is, as you would expect, simply in order of the args passed to `.format`\n",
    "similarly, `{name}` would be a kwarg  to `.format(name=...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a705477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"prompt = Prompt(\\n    \\\"\\\"\\\"Time: {time}\\nUser: {user_msg}\\nAssistant: Hello, {}{punctuation}\\nUser: Can you write me a poem about a superhero named pandaman being a friend to {}?\\nAssistant:{poem}\\nUser: What is 10+5?\\nAssistant: The answer is 10+5={math}\\n\\nThe final answer is {fin}!\\n\\nUser: Countdown from 5 to 0.\\nAssistant: 5, 4, {countdown}\\n\\n\\\"\\\"\\\",\\n    # Now the default completion parameters. See above for all the options\\n    # These are all optional, but at least a model would need to be specified to any given request for a completion by an LLM\\n    chat_model,  # default model when not otherwise specified\\n    stream=print_stream,  # default stream when not otherwise specified\\n    max_tokens=25,  # the default number of max tokens\\n    map_fn=my_log_function,  # default map_fn. if a map_fn is not specified for specific completions, this will run on the completion\\n)\";\n",
       "                var nbb_formatted_code = \"prompt = Prompt(\\n    \\\"\\\"\\\"Time: {time}\\nUser: {user_msg}\\nAssistant: Hello, {}{punctuation}\\nUser: Can you write me a poem about a superhero named pandaman being a friend to {}?\\nAssistant:{poem}\\nUser: What is 10+5?\\nAssistant: The answer is 10+5={math}\\n\\nThe final answer is {fin}!\\n\\nUser: Countdown from 5 to 0.\\nAssistant: 5, 4, {countdown}\\n\\n\\\"\\\"\\\",\\n    # Now the default completion parameters. See above for all the options\\n    # These are all optional, but at least a model would need to be specified to any given request for a completion by an LLM\\n    chat_model,  # default model when not otherwise specified\\n    stream=print_stream,  # default stream when not otherwise specified\\n    max_tokens=25,  # the default number of max tokens\\n    map_fn=my_log_function,  # default map_fn. if a map_fn is not specified for specific completions, this will run on the completion\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = Prompt(\n",
    "    \"\"\"Time: {time}\n",
    "User: {user_msg}\n",
    "Assistant: Hello, {}{punctuation}\n",
    "User: Can you write me a poem about a superhero named pandaman being a friend to {}?\n",
    "Assistant:{poem}\n",
    "User: What is 10+5?\n",
    "Assistant: The answer is 10+5={math}\n",
    "\n",
    "The final answer is {fin}!\n",
    "\n",
    "User: Countdown from 5 to 0.\n",
    "Assistant: 5, 4, {countdown}\n",
    "\n",
    "\"\"\",\n",
    "    # Now the default completion parameters. See above for all the options\n",
    "    # These are all optional, but at least a model would need to be specified to any given request for a completion by an LLM\n",
    "    chat_model,  # default model when not otherwise specified\n",
    "    stream=print_stream,  # default stream when not otherwise specified\n",
    "    max_tokens=25,  # the default number of max tokens\n",
    "    map_fn=my_log_function,  # default map_fn. if a map_fn is not specified for specific completions, this will run on the completion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12346cdd",
   "metadata": {},
   "source": [
    "# Now, we generate some completions.\n",
    "Here are the different types of arguments that can be passed to the .format() method on a prompt object:\n",
    "\n",
    "- Stringable: Any string or object that can be converted to a string, like str, int, etc. This just formats the prompt with that static string.\n",
    "\n",
    "- Callable[[Prompt], Union[Stringable, CompletionConfig]]: A callable that takes the Prompt as an argument and returns either a Stringable or CompletionConfig. This allows dynamically formatting the prompt based on the state of the Prompt.\n",
    "\n",
    "- Callable[[Prompt], Iterable[Union[Stringable, CompletionConfig]]]: A callable that takes the Prompt and returns an iterable of Stringable or CompletionConfig objects. This allows dynamically formatting the prompt with multiple components based on the state of the Prompt.\n",
    "\n",
    "TLDR:\n",
    "\n",
    "- Stringable: Static prompt string\n",
    "- Callable returning Stringable or CompletionConfig: Dynamic single component prompt\n",
    "- Callable returning iterable of Stringable or CompletionConfig: Dynamic multi-component prompt\n",
    "\n",
    "The Callable options allow the prompt to be customized dynamically based on the context. The CompletionConfig return allows configuring the completions directly in the prompt formatter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee48ee40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# First, we make a function that we will use to generate multiple completions in part of our prompt\\ndef countdown(prompt):\\n    while True:\\n        count = prompt.completions[\\\"countdown\\\"]\\n        count = count[-1] if isinstance(count, list) else count\\n        if count is None or int(count.strip(\\\", \\\")) > 0:\\n            yield CompletionConfig(\\n                llama_model,\\n                constraint=RegexConstraint(\\\"[0-9]\\\"),\\n                map_fn=lambda s: f\\\"{s}, \\\",\\n            )\\n        else:\\n            break\";\n",
       "                var nbb_formatted_code = \"# First, we make a function that we will use to generate multiple completions in part of our prompt\\ndef countdown(prompt):\\n    while True:\\n        count = prompt.completions[\\\"countdown\\\"]\\n        count = count[-1] if isinstance(count, list) else count\\n        if count is None or int(count.strip(\\\", \\\")) > 0:\\n            yield CompletionConfig(\\n                llama_model,\\n                constraint=RegexConstraint(\\\"[0-9]\\\"),\\n                map_fn=lambda s: f\\\"{s}, \\\",\\n            )\\n        else:\\n            break\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, we make a function that we will use to generate multiple completions in part of our prompt\n",
    "def countdown(prompt):\n",
    "    while True:\n",
    "        count = prompt.completions[\"countdown\"]\n",
    "        count = count[-1] if isinstance(count, list) else count\n",
    "        if count is None or int(count.strip(\", \")) > 0:\n",
    "            yield CompletionConfig(\n",
    "                llama_model,\n",
    "                constraint=RegexConstraint(\"[0-9]\"),\n",
    "                map_fn=lambda s: f\"{s}, \",\n",
    "            )\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d034bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='Time: ', value=`Time: `, start=0, stop=6, name=None, chunk=False, score=None)\n",
      "Completion(text='2023-07-23 13:21:48', value=`2023-07-23 13:21:48`, start=6, stop=25, name=None, chunk=False, score=None)\n",
      "Completion(text='\n",
      "User: ', value=`\n",
      "User: `, start=25, stop=32, name=None, chunk=False, score=None)\n",
      "Completion(text='Hi, my name is Nick.', value=`Hi, my name is Nick.`, start=32, stop=52, name=None, chunk=False, score=None)\n",
      "Completion(text='\n",
      "Assistant: Hello, ', value=`\n",
      "Assistant: Hello, `, start=52, stop=71, name=None, chunk=False, score=None)\n",
      "YO Nick\n",
      "Completion(text='!', value=`!`, start=75, stop=76, name=None, chunk=False, score=None)\n",
      "Completion(text='\n",
      "User: Can you write me a poem about a superhero named pandaman being a friend to ', value=`\n",
      "User: Can you write me a poem about a superhero named pandaman being a friend to `, start=76, stop=158, name=None, chunk=False, score=None)\n",
      "Completion(text='Nick', value=`Nick`, start=158, stop=162, name=None, chunk=False, score=None)\n",
      "Completion(text='?\n",
      "Assistant:', value=`?\n",
      "Assistant:`, start=162, stop=174, name=None, chunk=False, score=None)\n",
      "Completion(text=' Of', value=` Of`, start=177, stop=180, name=poem, chunk=True, score=0.9953406023210347)\n",
      "Completion(text=' course', value=` course`, start=184, stop=191, name=poem, chunk=True, score=0.9998168579168809)\n",
      "Completion(text=',', value=`,`, start=185, stop=186, name=poem, chunk=True, score=0.7205298905120724)\n",
      "Completion(text=' I', value=` I`, start=187, stop=189, name=poem, chunk=True, score=0.6047914772596368)\n",
      "Completion(text=''', value=`'`, start=188, stop=189, name=poem, chunk=True, score=0.9953930009322992)\n",
      "Completion(text='d', value=`d`, start=189, stop=190, name=poem, chunk=True, score=0.9871465136754854)\n",
      "Completion(text=' be', value=` be`, start=192, stop=195, name=poem, chunk=True, score=0.999946070500474)\n",
      "Completion(text=' happy', value=` happy`, start=198, stop=204, name=poem, chunk=True, score=0.998019201821986)\n",
      "Completion(text=' to', value=` to`, start=201, stop=204, name=poem, chunk=True, score=0.9999972978133075)\n",
      "Completion(text=' help', value=` help`, start=206, stop=211, name=poem, chunk=True, score=0.8858796133748004)\n",
      "Completion(text='!', value=`!`, start=207, stop=208, name=poem, chunk=True, score=0.7646994595088926)\n",
      "Completion(text=' Here', value=` Here`, start=212, stop=217, name=poem, chunk=True, score=0.9847613882844931)\n",
      "Completion(text=''', value=`'`, start=213, stop=214, name=poem, chunk=True, score=0.716412322769784)\n",
      "Completion(text='s', value=`s`, start=214, stop=215, name=poem, chunk=True, score=0.9999981023938415)\n",
      "Completion(text=' a', value=` a`, start=216, stop=218, name=poem, chunk=True, score=0.9999886926734525)\n",
      "Completion(text=' poem', value=` poem`, start=221, stop=226, name=poem, chunk=True, score=0.9327932825141483)\n",
      "Completion(text=' for', value=` for`, start=225, stop=229, name=poem, chunk=True, score=0.5743623958775382)\n",
      "Completion(text=' you', value=` you`, start=229, stop=233, name=poem, chunk=True, score=0.9922867802583779)\n",
      "Completion(text=':', value=`:`, start=230, stop=231, name=poem, chunk=True, score=0.9999868582816586)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=231, stop=232, name=poem, chunk=True, score=0.9999962306610736)\n",
      "Completion(text='P', value=`P`, start=232, stop=233, name=poem, chunk=True, score=0.7122267681974749)\n",
      "Completion(text='and', value=`and`, start=235, stop=238, name=poem, chunk=True, score=0.9906487019005489)\n",
      "Completion(text='aman', value=`aman`, start=239, stop=243, name=poem, chunk=True, score=0.9998448015696104)\n",
      "Completion(text=' and', value=` and`, start=243, stop=247, name=poem, chunk=True, score=0.15522491578820916)\n",
      "Completion(text=' Nick', value=` Nick`, start=248, stop=253, name=poem, chunk=True, score=0.9988037797018712)\n",
      "Completion(text=',', value=`,`, start=249, stop=250, name=poem, chunk=True, score=0.8698763301579678)\n",
      "Completion(text=' a', value=` a`, start=251, stop=253, name=poem, chunk=True, score=0.9505915091150132)\n",
      "Completion(text=' du', value=` du`, start=254, stop=257, name=poem, chunk=True, score=0.5415715537932295)\n",
      "Completion(text='o', value=`o`, start=255, stop=256, name=poem, chunk=True, score=0.9997793360867431)\n",
      "Completion(text=' so', value=` so`, start=258, stop=261, name=poem, chunk=True, score=0.7526218596498029)\n",
      "Completion(text=' fine', value=` fine`, start=263, stop=268, name=poem, chunk=True, score=0.5901031611407582)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=264, stop=265, name=poem, chunk=True, score=0.5455193861057396)\n",
      "Completion(text='T', value=`T`, start=265, stop=266, name=poem, chunk=True, score=0.5514782263905443)\n",
      "Completion(text='ogether', value=`ogether`, start=272, stop=279, name=poem, chunk=True, score=0.999628669088543)\n",
      "Completion(text=' they', value=` they`, start=277, stop=282, name=poem, chunk=True, score=0.9962519894935759)\n",
      "Completion(text=' fight', value=` fight`, start=283, stop=289, name=poem, chunk=True, score=0.5151516271912392)\n",
      "Completion(text=' crime', value=` crime`, start=289, stop=295, name=poem, chunk=True, score=0.8068441939754393)\n",
      "Completion(text=',', value=`,`, start=290, stop=291, name=poem, chunk=True, score=0.5731584251464099)\n",
      "Completion(text=' in', value=` in`, start=293, stop=296, name=poem, chunk=True, score=0.12063307491121757)\n",
      "Completion(text=' a', value=` a`, start=295, stop=297, name=poem, chunk=True, score=0.7796551094298526)\n",
      "Completion(text=' world', value=` world`, start=301, stop=307, name=poem, chunk=True, score=0.507052810922237)\n",
      "Completion(text=' that', value=` that`, start=306, stop=311, name=poem, chunk=True, score=0.2026863276873791)\n",
      "Completion(text=''', value=`'`, start=307, stop=308, name=poem, chunk=True, score=0.9722848405791981)\n",
      "Completion(text='s', value=`s`, start=308, stop=309, name=poem, chunk=True, score=0.9999960127068254)\n",
      "Completion(text=' all', value=` all`, start=312, stop=316, name=poem, chunk=True, score=0.2654840036589377)\n",
      "Completion(text=' the', value=` the`, start=316, stop=320, name=poem, chunk=True, score=0.8819045635303473)\n",
      "Completion(text=' time', value=` time`, start=321, stop=326, name=poem, chunk=True, score=0.9997233593472973)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=322, stop=323, name=poem, chunk=True, score=0.9974577455047018)\n",
      "Completion(text='With', value=`With`, start=326, stop=330, name=poem, chunk=True, score=0.1411422175209833)\n",
      "Completion(text=' P', value=` P`, start=328, stop=330, name=poem, chunk=True, score=0.7527752869656182)\n",
      "Completion(text='and', value=`and`, start=331, stop=334, name=poem, chunk=True, score=0.9951187808549106)\n",
      "Completion(text='aman', value=`aman`, start=335, stop=339, name=poem, chunk=True, score=0.999987462228457)\n",
      "Completion(text=''', value=`'`, start=336, stop=337, name=poem, chunk=True, score=0.9996891381505697)\n",
      "Completion(text='s', value=`s`, start=337, stop=338, name=poem, chunk=True, score=0.9999238483382851)\n",
      "Completion(text=' powers', value=` powers`, start=344, stop=351, name=poem, chunk=True, score=0.6984418238841672)\n",
      "Completion(text=',', value=`,`, start=345, stop=346, name=poem, chunk=True, score=0.7956074212718358)\n",
      "Completion(text=' he', value=` he`, start=348, stop=351, name=poem, chunk=True, score=0.7943773810313245)\n",
      "Completion(text=' saves', value=` saves`, start=354, stop=360, name=poem, chunk=True, score=0.26187603880694177)\n",
      "Completion(text=' the', value=` the`, start=358, stop=362, name=poem, chunk=True, score=0.9997159136007312)\n",
      "Completion(text=' day', value=` day`, start=362, stop=366, name=poem, chunk=True, score=0.9997459259962468)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=363, stop=364, name=poem, chunk=True, score=0.9978702223966965)\n",
      "Completion(text='And', value=`And`, start=366, stop=369, name=poem, chunk=True, score=0.9741263073582064)\n",
      "Completion(text=' Nick', value=` Nick`, start=371, stop=376, name=poem, chunk=True, score=0.9976409940886465)\n",
      "Completion(text=''', value=`'`, start=372, stop=373, name=poem, chunk=True, score=0.6470309280431105)\n",
      "Completion(text='s', value=`s`, start=373, stop=374, name=poem, chunk=True, score=0.9999915564272153)\n",
      "Completion(text=' bra', value=` bra`, start=377, stop=381, name=poem, chunk=True, score=0.5194644691843707)\n",
      "Completion(text='very', value=`very`, start=381, stop=385, name=poem, chunk=True, score=0.9988276592363194)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text=' never', value=` never`, start=387, stop=393, name=poem, chunk=True, score=0.1293395656144212)\n",
      "Completion(text=' f', value=` f`, start=389, stop=391, name=poem, chunk=True, score=0.8823310443857968)\n",
      "Completion(text='ades', value=`ades`, start=393, stop=397, name=poem, chunk=True, score=0.9999213726735293)\n",
      "Completion(text=' away', value=` away`, start=398, stop=403, name=poem, chunk=True, score=0.9716234448822089)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=399, stop=400, name=poem, chunk=True, score=0.9998801543766082)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=400, stop=401, name=poem, chunk=True, score=0.9919227154387406)\n",
      "Completion(text='They', value=`They`, start=404, stop=408, name=poem, chunk=True, score=0.5245169250239743)\n",
      "Completion(text=' stand', value=` stand`, start=410, stop=416, name=poem, chunk=True, score=0.1955426682336281)\n",
      "Completion(text=' tall', value=` tall`, start=415, stop=420, name=poem, chunk=True, score=0.35164224753290896)\n",
      "Completion(text=' against', value=` against`, start=423, stop=431, name=poem, chunk=True, score=0.08180569224086577)\n",
      "Completion(text=' the', value=` the`, start=427, stop=431, name=poem, chunk=True, score=0.9558765477129911)\n",
      "Completion(text=' night', value=` night`, start=433, stop=439, name=poem, chunk=True, score=0.530029150058417)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=434, stop=435, name=poem, chunk=True, score=0.9984370040034315)\n",
      "Completion(text='The', value=`The`, start=437, stop=440, name=poem, chunk=True, score=0.20239402386178945)\n",
      "Completion(text='ir', value=`ir`, start=439, stop=441, name=poem, chunk=True, score=0.9998193246278758)\n",
      "Completion(text=' friendship', value=` friendship`, start=450, stop=461, name=poem, chunk=True, score=0.7307963473767607)\n",
      "Completion(text=' sh', value=` sh`, start=453, stop=456, name=poem, chunk=True, score=0.8151767615594531)\n",
      "Completion(text='ining', value=`ining`, start=458, stop=463, name=poem, chunk=True, score=0.8835198455885288)\n",
      "Completion(text=' with', value=` with`, start=463, stop=468, name=poem, chunk=True, score=0.31997903656661403)\n",
      "Completion(text=' all', value=` all`, start=467, stop=471, name=poem, chunk=True, score=0.9778329618220375)\n",
      "Completion(text=' its', value=` its`, start=471, stop=475, name=poem, chunk=True, score=0.5986630808718043)\n",
      "Completion(text=' might', value=` might`, start=477, stop=483, name=poem, chunk=True, score=0.9987888788831633)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=478, stop=479, name=poem, chunk=True, score=0.9998228255296531)\n",
      "Completion(text='P', value=`P`, start=479, stop=480, name=poem, chunk=True, score=0.8019374872404208)\n",
      "Completion(text='and', value=`and`, start=482, stop=485, name=poem, chunk=True, score=0.9996206647233542)\n",
      "Completion(text='aman', value=`aman`, start=486, stop=490, name=poem, chunk=True, score=0.9999965784080308)\n",
      "Completion(text=' and', value=` and`, start=490, stop=494, name=poem, chunk=True, score=0.8325582899937731)\n",
      "Completion(text=' Nick', value=` Nick`, start=495, stop=500, name=poem, chunk=True, score=0.9999965875388076)\n",
      "Completion(text=',', value=`,`, start=496, stop=497, name=poem, chunk=True, score=0.999328057578627)\n",
      "Completion(text=' a', value=` a`, start=498, stop=500, name=poem, chunk=True, score=0.9579492851857168)\n",
      "Completion(text=' perfect', value=` perfect`, start=506, stop=514, name=poem, chunk=True, score=0.3338664985225214)\n",
      "Completion(text=' pair', value=` pair`, start=511, stop=516, name=poem, chunk=True, score=0.9863392145131201)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=512, stop=513, name=poem, chunk=True, score=0.9998893608042522)\n",
      "Completion(text='A', value=`A`, start=513, stop=514, name=poem, chunk=True, score=0.30351146680909746)\n",
      "Completion(text=' super', value=` super`, start=519, stop=525, name=poem, chunk=True, score=0.298688086472789)\n",
      "Completion(text='h', value=`h`, start=520, stop=521, name=poem, chunk=True, score=0.9973924380530568)\n",
      "Completion(text='ero', value=`ero`, start=523, stop=526, name=poem, chunk=True, score=0.9999903837233093)\n",
      "Completion(text=' du', value=` du`, start=526, stop=529, name=poem, chunk=True, score=0.569099056691791)\n",
      "Completion(text='o', value=`o`, start=527, stop=528, name=poem, chunk=True, score=0.998966015879032)\n",
      "Completion(text=' beyond', value=` beyond`, start=534, stop=541, name=poem, chunk=True, score=0.7518297193123977)\n",
      "Completion(text=' compare', value=` compare`, start=542, stop=550, name=poem, chunk=True, score=0.9998733811292214)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=543, stop=544, name=poem, chunk=True, score=0.9611427794353284)\n",
      "Completion(text='\n",
      "', value=`\n",
      "`, start=544, stop=545, name=poem, chunk=True, score=0.9974513527394322)\n",
      "Completion(text='User', value=`User`, start=548, stop=552, name=poem, chunk=True, score=0.3679730505894222)\n",
      "Completion(text='\n",
      "User: What is 10+5?\n",
      "Assistant: The answer is 10+5=', value=`\n",
      "User: What is 10+5?\n",
      "Assistant: The answer is 10+5=`, start=548, stop=599, name=None, chunk=False, score=None)\n",
      "Completion(text='1', value=`1`, start=600, stop=601, name=math, chunk=True, score=0.9999905368079026)\n",
      "Completion(text='5', value=`5`, start=601, stop=602, name=math, chunk=True, score=0.9999980104287338)\n",
      "Completion(text='1', value=`1`, start=602, stop=603, name=math, chunk=True, score=0.8224686691450454)\n",
      "Completion(text='1', value=`1`, start=603, stop=604, name=math, chunk=True, score=0.17172641003311795)\n",
      "Completion(text='5', value=`5`, start=604, stop=605, name=math, chunk=True, score=0.41761632737780946)\n",
      "Completion(text='1', value=`1`, start=605, stop=606, name=math, chunk=True, score=0.9473186703545964)\n",
      "Completion(text='1', value=`1`, start=606, stop=607, name=math, chunk=True, score=0.664143088572896)\n",
      "Completion(text='5', value=`5`, start=607, stop=608, name=math, chunk=True, score=0.9361435163075351)\n",
      "Completion(text='1', value=`1`, start=608, stop=609, name=math, chunk=True, score=0.9741078799671187)\n",
      "Completion(text='1', value=`1`, start=609, stop=610, name=math, chunk=True, score=0.9496576941098159)\n",
      "Completion(text='5', value=`5`, start=610, stop=611, name=math, chunk=True, score=0.9634796751970308)\n",
      "Completion(text='1', value=`1`, start=611, stop=612, name=math, chunk=True, score=0.9926158074198859)\n",
      "Completion(text='1', value=`1`, start=612, stop=613, name=math, chunk=True, score=0.9937118493007998)\n",
      "Completion(text='5', value=`5`, start=613, stop=614, name=math, chunk=True, score=0.946372051678055)\n",
      "Completion(text='1', value=`1`, start=614, stop=615, name=math, chunk=True, score=0.997085397952872)\n",
      "Completion(text='1', value=`1`, start=615, stop=616, name=math, chunk=True, score=0.9923244255450221)\n",
      "Completion(text='5', value=`5`, start=616, stop=617, name=math, chunk=True, score=0.9497259419524972)\n",
      "Completion(text='1', value=`1`, start=617, stop=618, name=math, chunk=True, score=0.9988172762962688)\n",
      "Completion(text='1', value=`1`, start=618, stop=619, name=math, chunk=True, score=0.9904376479586302)\n",
      "Completion(text='5', value=`5`, start=619, stop=620, name=math, chunk=True, score=0.8887719496617861)\n",
      "Completion(text='1', value=`1`, start=620, stop=621, name=math, chunk=True, score=0.9984610836485078)\n",
      "Completion(text='1', value=`1`, start=621, stop=622, name=math, chunk=True, score=0.979238015988958)\n",
      "Completion(text='5', value=`5`, start=622, stop=623, name=math, chunk=True, score=0.9187244444496172)\n",
      "Completion(text='1', value=`1`, start=623, stop=624, name=math, chunk=True, score=0.9987963402165977)\n",
      "Completion(text='1', value=`1`, start=624, stop=625, name=math, chunk=True, score=0.9754668685236573)\n",
      "Completion(text='\n",
      "\n",
      "The final answer is ', value=`\n",
      "\n",
      "The final answer is `, start=614, stop=636, name=None, chunk=False, score=None)\n",
      "Completion(text='1', value=`1`, start=637, stop=638, name=fin, chunk=True, score=0.9999995210892352)\n",
      "Completion(text='6', value=`6`, start=638, stop=639, name=fin, chunk=True, score=0.9999999085389886)\n",
      "Completion(text='!\n",
      "\n",
      "User: Countdown from 5 to 0.\n",
      "Assistant: 5, 4, ', value=`!\n",
      "\n",
      "User: Countdown from 5 to 0.\n",
      "Assistant: 5, 4, `, start=638, stop=687, name=None, chunk=False, score=None)\n",
      "Completion(text='3', value=`3`, start=688, stop=689, name=countdown, chunk=True, score=0.9999961988222579)\n",
      "Completion(text='2', value=`2`, start=691, stop=692, name=countdown, chunk=True, score=0.9999966829728378)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(text='1', value=`1`, start=694, stop=695, name=countdown, chunk=True, score=0.9999398111516474)\n",
      "Completion(text='0', value=`0`, start=697, stop=698, name=countdown, chunk=True, score=0.9999923831510504)\n",
      "Completion(text='\n",
      "\n",
      "', value=`\n",
      "\n",
      "`, start=699, stop=701, name=None, chunk=False, score=None)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"filled_in = await prompt.format(\\n    # request a model completion\\n    # note the lack of a specific model so it will use our default `chat_model` i.e. chatgpt\\n    # we also specify a custom constraint of options for the first unnamed completion {}\\n    CompletionConfig(constraint=OptionsConstraint({\\\"Sam\\\", \\\"Nick\\\"}), stream=yo_stream),\\n    # for the second unnamed completion, we want the value from the first, a plain callable allows that like so\\n    lambda p: p.completions[0],\\n    # Maybe the user calling the prompt wants to dynamically swap punctuation, you could make this a variable\\n    # we'll just call it a ! for now\\n    punctuation=\\\"!\\\",\\n    # we'll point to the user message however\\n    user_msg=user_message,\\n    # and make sure the llm knows the current time\\n    time=datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\"),\\n    # now, have llama write us a poem. it might be long so override our default `max_tokens`\\n    # and make sure the model stops if it tries to make a new User or Assistant marker to hallucinate the converstaion\\n    # don't include the start of the hallucination either\\n    poem=CompletionConfig(\\n        llama_model,\\n        max_tokens=250,\\n        constraint=StopsConstraint(\\\"User|Assistant\\\", include=False),\\n    ),\\n    # for some reason, let's see if it can answer a math problem and we will use our function that manipulates it and potentially injects the prompt with something else ridiculing the model\\n    math=CompletionConfig(\\n        llama_model,\\n        constraint=RegexConstraint(\\\"[0-9]+\\\", terminate_on_match=False),\\n        map_fn=store_my_math,\\n    ),\\n    #\\n    fin=lambda p: CompletionConfig(\\n        llama_model,\\n        constraint=RegexConstraint(rf\\\"{p.completions.math}|16\\\"),\\n    ),\\n    countdown=countdown,\\n)\";\n",
       "                var nbb_formatted_code = \"filled_in = await prompt.format(\\n    # request a model completion\\n    # note the lack of a specific model so it will use our default `chat_model` i.e. chatgpt\\n    # we also specify a custom constraint of options for the first unnamed completion {}\\n    CompletionConfig(constraint=OptionsConstraint({\\\"Sam\\\", \\\"Nick\\\"}), stream=yo_stream),\\n    # for the second unnamed completion, we want the value from the first, a plain callable allows that like so\\n    lambda p: p.completions[0],\\n    # Maybe the user calling the prompt wants to dynamically swap punctuation, you could make this a variable\\n    # we'll just call it a ! for now\\n    punctuation=\\\"!\\\",\\n    # we'll point to the user message however\\n    user_msg=user_message,\\n    # and make sure the llm knows the current time\\n    time=datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\"),\\n    # now, have llama write us a poem. it might be long so override our default `max_tokens`\\n    # and make sure the model stops if it tries to make a new User or Assistant marker to hallucinate the converstaion\\n    # don't include the start of the hallucination either\\n    poem=CompletionConfig(\\n        llama_model,\\n        max_tokens=250,\\n        constraint=StopsConstraint(\\\"User|Assistant\\\", include=False),\\n    ),\\n    # for some reason, let's see if it can answer a math problem and we will use our function that manipulates it and potentially injects the prompt with something else ridiculing the model\\n    math=CompletionConfig(\\n        llama_model,\\n        constraint=RegexConstraint(\\\"[0-9]+\\\", terminate_on_match=False),\\n        map_fn=store_my_math,\\n    ),\\n    #\\n    fin=lambda p: CompletionConfig(\\n        llama_model,\\n        constraint=RegexConstraint(rf\\\"{p.completions.math}|16\\\"),\\n    ),\\n    countdown=countdown,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in = await prompt.format(\n",
    "    # request a model completion\n",
    "    # note the lack of a specific model so it will use our default `chat_model` i.e. chatgpt\n",
    "    # we also specify a custom constraint of options for the first unnamed completion {}\n",
    "    CompletionConfig(constraint=OptionsConstraint({\"Sam\", \"Nick\"}), stream=yo_stream),\n",
    "    # for the second unnamed completion, we want the value from the first, a plain callable allows that like so\n",
    "    lambda p: p.completions[0],\n",
    "    # Maybe the user calling the prompt wants to dynamically swap punctuation, you could make this a variable\n",
    "    # we'll just call it a ! for now\n",
    "    punctuation=\"!\",\n",
    "    # we'll point to the user message however\n",
    "    user_msg=user_message,\n",
    "    # and make sure the llm knows the current time\n",
    "    time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    # now, have llama write us a poem. it might be long so override our default `max_tokens`\n",
    "    # and make sure the model stops if it tries to make a new User or Assistant marker to hallucinate the converstaion\n",
    "    # don't include the start of the hallucination either\n",
    "    poem=CompletionConfig(\n",
    "        llama_model,\n",
    "        max_tokens=250,\n",
    "        constraint=StopsConstraint(\"User|Assistant\", include=False),\n",
    "    ),\n",
    "    # for some reason, let's see if it can answer a math problem and we will use our function that manipulates it and potentially injects the prompt with something else ridiculing the model\n",
    "    math=CompletionConfig(\n",
    "        llama_model,\n",
    "        constraint=RegexConstraint(\"[0-9]+\", terminate_on_match=False),\n",
    "        map_fn=store_my_math,\n",
    "    ),\n",
    "    #\n",
    "    fin=lambda p: CompletionConfig(\n",
    "        llama_model,\n",
    "        constraint=RegexConstraint(rf\"{p.completions.math}|16\"),\n",
    "    ),\n",
    "    countdown=countdown,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b152263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt('Time: 2023-07-23 13:21:48\n",
       "User: Hi, my name is Nick.\n",
       "Assistant: Hello, Nick!\n",
       "User: Can you write me a poem about a superhero named pandaman being a friend to Nick?\n",
       "Assistant: Of course, I'd be happy to help! Here's a poem for you:\n",
       "Pandaman and Nick, a duo so fine\n",
       "Together they fight crime, in a world that's all the time\n",
       "With Pandaman's powers, he saves the day\n",
       "And Nick's bravery never fades away\n",
       "\n",
       "They stand tall against the night\n",
       "Their friendship shining with all its might\n",
       "Pandaman and Nick, a perfect pair\n",
       "A superhero duo beyond compare\n",
       "\n",
       "User\n",
       "User: What is 10+5?\n",
       "Assistant: The answer is 10+5=Duh me no know.\n",
       "\n",
       "The final answer is 16!\n",
       "\n",
       "User: Countdown from 5 to 0.\n",
       "Assistant: 5, 4, 3, 2, 1, 0, \n",
       "\n",
       "')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"filled_in\";\n",
       "                var nbb_formatted_code = \"filled_in\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cf61a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(text=' Of course, I'd be happy to help! Here's a poem for you:\n",
       "Pandaman and Nick, a duo so fine\n",
       "Together they fight crime, in a world that's all the time\n",
       "With Pandaman's powers, he saves the day\n",
       "And Nick's bravery never fades away\n",
       "\n",
       "They stand tall against the night\n",
       "Their friendship shining with all its might\n",
       "Pandaman and Nick, a perfect pair\n",
       "A superhero duo beyond compare\n",
       "\n",
       "User', value=` Of course, I'd be happy to help! Here's a poem for you:\n",
       "Pandaman and Nick, a duo so fine\n",
       "Together they fight crime, in a world that's all the time\n",
       "With Pandaman's powers, he saves the day\n",
       "And Nick's bravery never fades away\n",
       "\n",
       "They stand tall against the night\n",
       "Their friendship shining with all its might\n",
       "Pandaman and Nick, a perfect pair\n",
       "A superhero duo beyond compare\n",
       "\n",
       "User`, start=174, stop=548, name=poem, chunk=False, score=1.3717268211743214e-17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"filled_in.completions.poem\";\n",
       "                var nbb_formatted_code = \"filled_in.completions.poem\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in.completions.poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ff6048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3, ', '2, ', '1, ', '0, ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"filled_in.completions.countdown\";\n",
       "                var nbb_formatted_code = \"filled_in.completions.countdown\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filled_in.completions.countdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
